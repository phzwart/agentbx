âœ¨ Add classic SyncGeometryAgent: external gradient/loss PyTorch pattern

ğŸ†• Introduce SyncGeometryAgent, a classic PyTorch-style synchronous agent for geometry minimization.

ğŸ”¬ Pattern:
  - .forward() computes and returns only the energy/loss as a scalar tensor.
  - .backward() computes and sets gradients in .grad using the external CCTBX engine.
  - Optimizer loop (Adam/SGD):
      1ï¸âƒ£ optimizer.zero_grad()
      2ï¸âƒ£ loss = agent.forward()
      3ï¸âƒ£ agent.backward()
      4ï¸âƒ£ optimizer.step()
  - LBFGS closure uses the same split: computes loss in .forward(), sets gradients in .backward(), returns loss.

âš¡ï¸ Features:
- No PyTorch autograd: gradients are set manually from CCTBX.
- Tracks energy and gradient call counts.
- Logs learning rate at each iteration.
- Supports learning rate schedulers (CyclicLR, StepLR, etc).
- Clear comments and docstrings clarify the external gradient pattern for future maintainers.

ğŸ“ This pattern is as close as possible to standard PyTorch, but adapted for external (non-autograd) gradient engines.
